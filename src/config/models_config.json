{
  "ollama": {
    "llama3.2:1b": {
      "name": "Llama 3.2 1B",
      "provider": "ollama",
      "speed": "fast",
      "complexity": "simple",
      "use_case": "Fast responses, simple queries",
      "size": "1B parameters"
    },
    "llama3.2:3b": {
      "name": "Llama 3.2 3B",
      "provider": "ollama",
      "speed": "medium",
      "complexity": "simple",
      "use_case": "Balanced performance",
      "size": "3B parameters"
    },
    "phi3": {
      "name": "Phi-3",
      "provider": "ollama",
      "speed": "fast",
      "complexity": "simple",
      "use_case": "Fast, efficient responses",
      "size": "3.8B parameters"
    },
    "mistral:7b": {
      "name": "Mistral 7B",
      "provider": "ollama",
      "speed": "medium",
      "complexity": "medium",
      "use_case": "Good balance",
      "size": "7B parameters"
    },
    "mixtral:8x7b": {
      "name": "Mixtral 8x7B",
      "provider": "ollama",
      "speed": "slow",
      "complexity": "complex",
      "use_case": "Complex reasoning, analysis",
      "size": "8x7B parameters"
    }
  },
  "huggingface": {
    "microsoft/Phi-3-mini-4k-instruct": {
      "name": "Phi-3 Mini",
      "provider": "huggingface",
      "speed": "fast",
      "complexity": "simple",
      "use_case": "Fast local inference",
      "size": "3.8B parameters"
    },
    "Qwen/Qwen2.5-7B-Instruct": {
      "name": "Qwen 2.5 7B",
      "provider": "huggingface",
      "speed": "medium",
      "complexity": "medium",
      "use_case": "Good performance",
      "size": "7B parameters"
    }
  },
  "openai": {
    "gpt-3.5-turbo": {
      "name": "GPT-3.5 Turbo",
      "provider": "openai",
      "speed": "fast",
      "complexity": "medium",
      "use_case": "Fast API responses",
      "size": "API"
    },
    "gpt-4": {
      "name": "GPT-4",
      "provider": "openai",
      "speed": "medium",
      "complexity": "complex",
      "use_case": "Complex reasoning",
      "size": "API"
    }
  }
}

